{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Gen AI APP Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "# ## Langsmith Tracking\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaibhavarde/Desktop/AgentKrish/AgentNotes/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "## Data Ingestion--From the website we need to scrape the data\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x132f3b090>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=WebBaseLoader(\"https://flowcv.com/resume/0ggnhcsp3u\")\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "FILE_PATH = \"https://flowcv.com/resume/0ggnhcsp3u\"\n",
    "\n",
    "loader = DoclingLoader(file_path=FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:02:45,776 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-25 11:02:45,795 - INFO - Going to convert document batch...\n",
      "2025-11-25 11:02:45,796 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-11-25 11:02:45,826 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2025-11-25 11:02:45,826 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-25 11:02:45,831 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-11-25 11:02:45,832 - INFO - Processing document 0ggnhcsp3u\n",
      "2025-11-25 11:02:45,845 - INFO - Finished converting document 0ggnhcsp3u in 0.44 sec.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/1', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/2', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/3', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/4', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/5', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/6', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/7', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content='Download\\nThere was an error. Please try in a few minutes again.\\nPrathamesh Sunil Patil Agentic AI Engineer\\n[Email [email protected]](/cdn-cgi/l/email-protection#0e7e7c6f7a666f637e6f7a6762373937364e69636f6762206d6163)\\n[Phone +91 9257589797](tel:+91 9257589797)\\n[linkedin.com/in/prathmeshpatil98](https://linkedin.com/in/prathmeshpatil98)\\nProfile'),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/8', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/9', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/10', 'parent': {'$ref': '#/groups/1'}, 'children': [{'$ref': '#/groups/2'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/15', 'parent': {'$ref': '#/groups/1'}, 'children': [{'$ref': '#/groups/3'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/20', 'parent': {'$ref': '#/groups/4'}, 'children': [{'$ref': '#/groups/5'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content='Equipped With a strong foundation in Python Programming, Deep Learning , Machine Learning and NLP. I am passionate about developing and optimizing large language models (LLMs), with particular focus on GenAI systems, prompt engineering and RAG architectures. Proven track record in developing RAG systems, autonomous agents and real world LLM applications using LangChain, LangGraph and FastAPI. I aim to advance LLM capabilities and extract insights from complex data. Eager to contribute to impactful AI projects, I seek opportunities to drive organizational growth through cutting edge technologies while fostering collaboration in cross functional teams.\\nCertifications\\n- • **Foundations of Prompt Engineering** - *IBM*\\n- • **AI Agents Using RAG and LangChain** - *IBM*\\n- • **Generative AI for Data Scientists** - *IBM*'),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/25', 'parent': {'$ref': '#/groups/6'}, 'children': [{'$ref': '#/groups/7'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/30', 'parent': {'$ref': '#/groups/6'}, 'children': [{'$ref': '#/groups/8'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/34', 'parent': {'$ref': '#/groups/6'}, 'children': [{'$ref': '#/groups/9'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/39', 'parent': {'$ref': '#/groups/6'}, 'children': [{'$ref': '#/groups/10'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/44', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/45', 'parent': {'$ref': '#/groups/11'}, 'children': [{'$ref': '#/groups/12'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/49', 'parent': {'$ref': '#/groups/11'}, 'children': [{'$ref': '#/groups/13'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/53', 'parent': {'$ref': '#/groups/14'}, 'children': [{'$ref': '#/groups/15'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/57', 'parent': {'$ref': '#/groups/16'}, 'children': [{'$ref': '#/groups/17'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/61', 'parent': {'$ref': '#/groups/18'}, 'children': [{'$ref': '#/groups/19'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content=\"- • **Generative AI with LLM's** - [*DeepLearning.AI*](http://deeplearning.ai/)\\n- • **Introduction to Large Language model -** Google\\n- • **Python** - *AlmaBetter , Narest IT Hydrabad*\\n- • **Deep Learning & NLP** - *AlmaBetter*\\nSkills\\n- • **Programming Languages:** Python\\n- • **Prompt Engineering** : Zero/Few shot, CoT\\n- • **LLM & Agent Tools:** N8N , LangGraph, Hugging Face, OpenAI, Ollama, Groq , RAG, MCP\\n- • **Cloud & MLOps:** Azure, Docker, Git, Langfuse.\\n- • **Soft Skills:** Problem solving , Attention to Detail, Independent Execution, Creative Thinking.\"),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content=\"professional Experience AI - Prompt Engineer [ Scale AI ] (Jun 2024 - Oct 2025 ) California US, Remote • As a Freelance Prompt Engineer Revised AI generated responses to ensure they are Correct, clear and relevant to user queries. • Validated AI generated Python and Mathematical solutions, ensuring accuracy and logical consistency. • Created zero shot, few shot and CoT templates to boost accuracy and consistency. • Conducted Python code reviews, debugging errors to improve model reliability. • Performed QA on datasets and responses, refining LLM outputs for clarity, correctness and alignment. • Evaluations of AI model & LLM responses and providing insights for continuous improvement with RLHF and A/B testing to enhance LLM (Large Language Model) performance, reduce hallucinations and improve safety. Data Science Trainee [ AlmaBetter ] • Implemented data-driven solutions using data manipulation and visualization tools . • Developed expertise in ML through hands-on projects, mastering Python and ML & DL frameworks . • Hands on Open source LLM's models using Hugging face and Langchain . Projects Terminal Based AI Voice Curser . • Developed Codexa a voice controlled AI coding assistant that generates production ready applications in real time. • Utilized LangGraph for\"),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content='workflow orchestration with state machine architecture and event driven design. • Integrated Groq LLM API, speech recognition and Coqui TTS for seamless voice interaction and code generation. • Implemented intelligent error handling, modular architecture and interactive code review features for robust development. AI Chat Agent - Facebook Messenger. (N8N) • Developed a AI agent with dual personas: one offering professional support for Facebook Page users and another delivering casual, engaging or flirty interactions for DMs. • Integrated workflow automation using n8n and Groq LLMs for fast context aware language responses. • Implemented smart message routing, memory based user context and dynamic response formatting for real time engagement. • Enhanced user experience by combining natural dialogue flow with strategic persona switching based on message type. Trading Chatbot for Financial Firm • Designed a trading assistant chatbot using ChatGroq (LLaMA 3.1-8B), LangChain and Ollama embeddings. • Utilized Langchain for document loading, text splitting and conversational retrieval chain creation. • We will build an LLM based question and answer system that can reduce the workload of their customer care staff. • User should be able to use this system to ask questions directly and'),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/66', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/67', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/68', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content='get answers within seconds . Education\\nBachelor of science (Mathematics ) Master In Data Science\\nShivaji University , Kolhapur                                                       Vellore institude of Technology ( VIT )\\nmarch 2020 - march 2023                                                          2024 - Present   ( Online )')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Data--> Docs-->Divide our Docuemnts into chunks dcouments-->text-->vectors-->Vector Embeddings--->Vector Store DB\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/1', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/2', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/3', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/4', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/5', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/6', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/7', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content='Download\\nThere was an error. Please try in a few minutes again.\\nPrathamesh Sunil Patil Agentic AI Engineer\\n[Email [email protected]](/cdn-cgi/l/email-protection#0e7e7c6f7a666f637e6f7a6762373937364e69636f6762206d6163)\\n[Phone +91 9257589797](tel:+91 9257589797)\\n[linkedin.com/in/prathmeshpatil98](https://linkedin.com/in/prathmeshpatil98)\\nProfile'),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/8', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/9', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/10', 'parent': {'$ref': '#/groups/1'}, 'children': [{'$ref': '#/groups/2'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/15', 'parent': {'$ref': '#/groups/1'}, 'children': [{'$ref': '#/groups/3'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/20', 'parent': {'$ref': '#/groups/4'}, 'children': [{'$ref': '#/groups/5'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content='Equipped With a strong foundation in Python Programming, Deep Learning , Machine Learning and NLP. I am passionate about developing and optimizing large language models (LLMs), with particular focus on GenAI systems, prompt engineering and RAG architectures. Proven track record in developing RAG systems, autonomous agents and real world LLM applications using LangChain, LangGraph and FastAPI. I aim to advance LLM capabilities and extract insights from complex data. Eager to contribute to impactful AI projects, I seek opportunities to drive organizational growth through cutting edge technologies while fostering collaboration in cross functional teams.\\nCertifications\\n- • **Foundations of Prompt Engineering** - *IBM*\\n- • **AI Agents Using RAG and LangChain** - *IBM*\\n- • **Generative AI for Data Scientists** - *IBM*'),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/25', 'parent': {'$ref': '#/groups/6'}, 'children': [{'$ref': '#/groups/7'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/30', 'parent': {'$ref': '#/groups/6'}, 'children': [{'$ref': '#/groups/8'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/34', 'parent': {'$ref': '#/groups/6'}, 'children': [{'$ref': '#/groups/9'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/39', 'parent': {'$ref': '#/groups/6'}, 'children': [{'$ref': '#/groups/10'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/44', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/45', 'parent': {'$ref': '#/groups/11'}, 'children': [{'$ref': '#/groups/12'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/49', 'parent': {'$ref': '#/groups/11'}, 'children': [{'$ref': '#/groups/13'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/53', 'parent': {'$ref': '#/groups/14'}, 'children': [{'$ref': '#/groups/15'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/57', 'parent': {'$ref': '#/groups/16'}, 'children': [{'$ref': '#/groups/17'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}, {'self_ref': '#/texts/61', 'parent': {'$ref': '#/groups/18'}, 'children': [{'$ref': '#/groups/19'}], 'content_layer': 'body', 'label': 'list_item', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content=\"- • **Generative AI with LLM's** - [*DeepLearning.AI*](http://deeplearning.ai/)\\n- • **Introduction to Large Language model -** Google\\n- • **Python** - *AlmaBetter , Narest IT Hydrabad*\\n- • **Deep Learning & NLP** - *AlmaBetter*\\nSkills\\n- • **Programming Languages:** Python\\n- • **Prompt Engineering** : Zero/Few shot, CoT\\n- • **LLM & Agent Tools:** N8N , LangGraph, Hugging Face, OpenAI, Ollama, Groq , RAG, MCP\\n- • **Cloud & MLOps:** Azure, Docker, Git, Langfuse.\\n- • **Soft Skills:** Problem solving , Attention to Detail, Independent Execution, Creative Thinking.\"),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content='professional Experience AI - Prompt Engineer [ Scale AI ] (Jun 2024 - Oct 2025 ) California US, Remote • As a Freelance Prompt Engineer Revised AI generated responses to ensure they are Correct, clear and relevant to user queries. • Validated AI generated Python and Mathematical solutions, ensuring accuracy and logical consistency. • Created zero shot, few shot and CoT templates to boost accuracy and consistency. • Conducted Python code reviews, debugging errors to improve model reliability. • Performed QA on datasets and responses, refining LLM outputs for clarity, correctness and alignment. • Evaluations of AI model & LLM responses and providing insights for continuous improvement with RLHF and A/B testing to enhance LLM (Large Language Model) performance, reduce hallucinations and improve safety. Data Science Trainee [ AlmaBetter ] • Implemented data-driven solutions using data manipulation and visualization tools . • Developed expertise in ML through hands-on projects, mastering'),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content=\"safety. Data Science Trainee [ AlmaBetter ] • Implemented data-driven solutions using data manipulation and visualization tools . • Developed expertise in ML through hands-on projects, mastering Python and ML & DL frameworks . • Hands on Open source LLM's models using Hugging face and Langchain . Projects Terminal Based AI Voice Curser . • Developed Codexa a voice controlled AI coding assistant that generates production ready applications in real time. • Utilized LangGraph for\"),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content='workflow orchestration with state machine architecture and event driven design. • Integrated Groq LLM API, speech recognition and Coqui TTS for seamless voice interaction and code generation. • Implemented intelligent error handling, modular architecture and interactive code review features for robust development. AI Chat Agent - Facebook Messenger. (N8N) • Developed a AI agent with dual personas: one offering professional support for Facebook Page users and another delivering casual, engaging or flirty interactions for DMs. • Integrated workflow automation using n8n and Groq LLMs for fast context aware language responses. • Implemented smart message routing, memory based user context and dynamic response formatting for real time engagement. • Enhanced user experience by combining natural dialogue flow with strategic persona switching based on message type. Trading Chatbot for Financial Firm • Designed a trading assistant chatbot using ChatGroq (LLaMA 3.1-8B), LangChain and Ollama'),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content='dialogue flow with strategic persona switching based on message type. Trading Chatbot for Financial Firm • Designed a trading assistant chatbot using ChatGroq (LLaMA 3.1-8B), LangChain and Ollama embeddings. • Utilized Langchain for document loading, text splitting and conversational retrieval chain creation. • We will build an LLM based question and answer system that can reduce the workload of their customer care staff. • User should be able to use this system to ask questions directly and'),\n",
       " Document(metadata={'source': 'https://flowcv.com/resume/0ggnhcsp3u', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/65', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/66', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/67', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}, {'self_ref': '#/texts/68', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': []}], 'origin': {'mimetype': 'text/html', 'binary_hash': 2131092609680125004, 'filename': '0ggnhcsp3u'}}}, page_content='get answers within seconds . Education\\nBachelor of science (Mathematics ) Master In Data Science\\nShivaji University , Kolhapur                                                       Vellore institude of Technology ( VIT )\\nmarch 2020 - march 2023                                                          2024 - Present   ( Online )')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings=OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Load free local embedding model\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:03:11,178 - INFO - Use pytorch device_name: mps\n",
      "2025-11-25 11:03:11,178 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings1 = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoredb=FAISS.from_documents(documents,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoredb1=FAISS.from_documents(documents,embeddings1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x138986510>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x13df39450>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Prathamesh Sunil PatilAgentic AI EngineerEmail[email\\xa0protected] Phone+91 9257589797 linkedin.com/in/prathmeshpatil98 ProfileEquipped With a strong foundation in Python Programming, Deep Learning , Machine Learning and NLP. I am passionate about developing and optimizing large language models (LLMs), with particular focus on GenAI systems, prompt engineering and RAG architectures. Proven track record in developing RAG systems, autonomous agents and real world LLM applications using LangChain, LangGraph and FastAPI. I aim to advance LLM capabilities and extract insights from complex data. Eager to contribute to impactful AI projects, I seek opportunities to drive organizational growth through cutting edge technologies while fostering collaboration in cross functional teams.Certifications•Foundations of Prompt Engineering – IBM•AI Agents Using RAG and LangChain – IBM•Generative AI for Data Scientists – IBM•Generative AI with LLM's  – DeepLearning.AI•Introduction to Large Language\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Query From a vector db\n",
    "query=\"Tell me about Prathamesh's skills\"\n",
    "result=vectorstoredb.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"- • **Generative AI with LLM's** - [*DeepLearning.AI*](http://deeplearning.ai/)\\n- • **Introduction to Large Language model -** Google\\n- • **Python** - *AlmaBetter , Narest IT Hydrabad*\\n- • **Deep Learning & NLP** - *AlmaBetter*\\nSkills\\n- • **Programming Languages:** Python\\n- • **Prompt Engineering** : Zero/Few shot, CoT\\n- • **LLM & Agent Tools:** N8N , LangGraph, Hugging Face, OpenAI, Ollama, Groq , RAG, MCP\\n- • **Cloud & MLOps:** Azure, Docker, Git, Langfuse.\\n- • **Soft Skills:** Problem solving , Attention to Detail, Independent Execution, Creative Thinking.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Query From a vector db\n",
    "query=\"Tell me about Prathamesh's skills\"\n",
    "result=vectorstoredb1.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0 0.4.1\n"
     ]
    }
   ],
   "source": [
    "import langchain; import langchain_community\n",
    "print(langchain.__version__, langchain_community.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "# from langchain_openai import ChatOpenAI  # Use your chosen LLM wrapper\n",
    "\n",
    "# llm = ChatOpenAI()   # Or other supported LLM\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "# Answer the following question based only on the provided context:\n",
    "# <context>\n",
    "# {context}\n",
    "# </context>\n",
    "# Question: {input}\n",
    "# \"\"\")\n",
    "\n",
    "# document_chain = create_stuff_documents_chain(\n",
    "#     llm=llm,\n",
    "#     prompt=prompt,\n",
    "#     document_separator=\"\\n\\n\",      # Optional: customize separator\n",
    "#     document_variable_name=\"context\" # match your prompt field\n",
    "# )\n",
    "\n",
    "# # Usage example (requires retriever integration for full RAG)\n",
    "# result = document_chain.invoke({\n",
    "#     \"input\": \"YOUR QUESTION HERE\",\n",
    "#     \"context\": [your_documents],    # List of Document objects\n",
    "# })\n",
    "\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True} client=<groq.resources.chat.completions.Completions object at 0x13e85b350> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x13e7b6c90> model_name='openai/gpt-oss-120b' model_kwargs={} groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"openai/gpt-oss-120b\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Retrieval Chain, Document chain\n",
    "\n",
    "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Answer the following question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "# document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "document_chain=prompt|llm|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-11-25 11:31:15,934 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LangSmith’s two usage limits are **total traces** and **extended traces**.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document_chain.invoke({\n",
    "    \"input\":\"LangSmith has two usage limits: total traces and extended\",\n",
    "    \"context\":[Document(page_content=\"LangSmith has two usage limits: total traces and extended traces. These correspond to the two metrics we've been tracking on our usage graph. \")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we want the documents to first come from the retriever we just set up. That way, we can use the retriever to dynamically select the most relevant documents and pass those in for a given question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x13df39450>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Input--->Retriever--->vectorstoredb\n",
    "\n",
    "vectorstoredb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever=vectorstoredb1.as_retriever()\n",
    "# from langchain.chains import create_retrieval_chain\n",
    "# retrieval_chain=create_retrieval_chain(retriever,document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the response form the LLM\n",
    "# response=retrieval_chain.invoke({\"input\":\"LangSmith has two usage limits: total traces and extended\"})\n",
    "# response['answer']\n",
    "\n",
    "# response=document_chain.invoke({\"input\":\"Can you tell me about Prathamesh in 20 words?\"})\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:56:42,210 - INFO - Use pytorch device_name: mps\n",
      "2025-11-25 11:56:42,211 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2025-11-25 11:56:47,510 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANSWER:\n",
      " **Skills listed for Prathamesh Sunil Patil**\n",
      "\n",
      "- **Programming Languages:** Python  \n",
      "- **Prompt Engineering:** Zero‑shot, Few‑shot, Chain‑of‑Thought (CoT)  \n",
      "- **LLM & Agent Tools:** N8N, LangGraph, Hugging Face, OpenAI, Ollama, Groq, Retrieval‑Augmented Generation (RAG), MCP  \n",
      "- **Cloud & MLOps:** Azure, Docker, Git, Langfuse  \n",
      "- **Soft Skills:** Problem solving, Attention to detail, Independent execution, Creative thinking  \n",
      "\n",
      "(These skills are taken directly from the “Skills” section of his resume.)\n"
     ]
    }
   ],
   "source": [
    "# ✅ LangChain v1.0 — FAISS + as_retriever() + Runnable RAG (working)\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ✅ 1) Embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# ✅ 2) Create FAISS vector store\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# ✅ 3) Convert to retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "# ✅ 4) Prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer using ONLY the following context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "# ✅ 5) Correct Runnable RAG pipeline\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"input\") | retriever,\n",
    "        \"input\": itemgetter(\"input\")\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ✅ 6) Run\n",
    "response = rag_chain.invoke({\"input\": \"what skills do Prathamesh hve?\"})\n",
    "\n",
    "print(\"\\nANSWER:\\n\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentnotes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

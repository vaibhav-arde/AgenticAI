{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "In this video We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "- Agents: Build a chatbot that can take actions\n",
    "\n",
    "This video tutorial will cover the basics which will be helpful for those two more advanced topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## aloading all the environment variable\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"openai/gpt-oss-120b\",groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello VaibhaV! It‚Äôs great to meet you. As a Chief AI Engineer, you must be working on some fascinating projects. How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says \"Hi , My name is VaibhaV and I am a Chief AI Engineer\". Likely they want a response, maybe a greeting. No request for disallowed content. So respond politely.'}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 87, 'total_tokens': 175, 'completion_time': 0.182214664, 'completion_tokens_details': {'reasoning_tokens': 44}, 'prompt_time': 0.003211255, 'prompt_tokens_details': None, 'queue_time': 0.047366075, 'total_time': 0.185425919}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_1d1727abc9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--f034be18-73b9-4de7-b382-b6f614cb9ee6-0', usage_metadata={'input_tokens': 87, 'output_tokens': 88, 'total_tokens': 175, 'output_token_details': {'reasoning': 44}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi , My name is VaibhaV and I am a Chief AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I don‚Äôt have any information about you unless you share it with me. Feel free to tell me a bit about yourself or let me know how I can help!', additional_kwargs={'reasoning_content': 'The user asks: \"Hi do you know who I am?\" There\\'s no context. According to policy, we can respond politely, ask for clarification. No disallowed content. So answer politely: I don\\'t know, ask them to introduce themselves.'}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 79, 'total_tokens': 171, 'completion_time': 0.205034314, 'completion_tokens_details': {'reasoning_tokens': 50}, 'prompt_time': 0.002993022, 'prompt_tokens_details': None, 'queue_time': 0.051186178, 'total_time': 0.208027336}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_70d048ba3c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--8f217325-3486-4aa8-a553-d7a447503402-0', usage_metadata={'input_tokens': 79, 'output_tokens': 92, 'total_tokens': 171, 'output_token_details': {'reasoning': 50}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi do you know who I am?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is **VaibhaV**, and you work as a **Chief AI Engineer**.', additional_kwargs={'reasoning_content': 'The user asks: \"Hey What\\'s my name and what do I do?\" The conversation: user introduced themselves as \"Hi , My name is VaibhaV and I am a Chief AI Engineer\". So answer: your name is VaibhaV and you are a Chief AI Engineer. Should respond accordingly.'}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 156, 'total_tokens': 248, 'completion_time': 0.19342393, 'completion_tokens_details': {'reasoning_tokens': 63}, 'prompt_time': 0.005851851, 'prompt_tokens_details': None, 'queue_time': 0.051673969, 'total_time': 0.199275781}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--6150c49d-4210-4409-a78b-6bbca8c7d744-0', usage_metadata={'input_tokens': 156, 'output_tokens': 92, 'total_tokens': 248, 'output_token_details': {'reasoning': 63}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi , My name is VaibhaV and I am a Chief AI Engineer\"),\n",
    "        AIMessage(content=\"Hello VaibhaV! It's nice to meet you. \\n\\nAs a Chief AI Engineer, what kind of projects are you working on these days? \\n\\nI'm always eager to learn more about the exciting work being done in the field of AI.\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.11.11 environment at: /Users/vaibhavarde/Desktop/AgentKrish/AgentNotes/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 86ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'chat1'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , My name is VaibhaV and I am a Chief AI Engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello VaibhaV! It‚Äôs great to meet you. How can I assist you today?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi , My name is VaibhaV and I am a Chief AI Engineer', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello VaibhaV! It‚Äôs great to meet you. How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says: \"Hi , My name is VaibhaV and I am a Chief AI Engineer\". Likely they are just greeting. The assistant should respond politely. No policy issues.'}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 87, 'total_tokens': 156, 'completion_time': 0.148574634, 'completion_tokens_details': {'reasoning_tokens': 40}, 'prompt_time': 0.003219431, 'prompt_tokens_details': None, 'queue_time': 0.051090589, 'total_time': 0.151794065}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--dfb9f81d-6f1a-44dd-8ae7-d960c3ac17c2-0', usage_metadata={'input_tokens': 87, 'output_tokens': 69, 'total_tokens': 156, 'output_token_details': {'reasoning': 40}})])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is VaibhaV.', additional_kwargs={'reasoning_content': 'User asks \"What\\'s my name?\" They introduced themselves as VaibhaV. So answer: VaibhaV.'}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 121, 'total_tokens': 163, 'completion_time': 0.087330393, 'completion_tokens_details': {'reasoning_tokens': 25}, 'prompt_time': 0.004643322, 'prompt_tokens_details': None, 'queue_time': 0.051253518, 'total_time': 0.091973715}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ede716ed-7410-40ac-8ef8-d647e809ad55-0', usage_metadata={'input_tokens': 121, 'output_tokens': 42, 'total_tokens': 163, 'output_token_details': {'reasoning': 25}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi , My name is VaibhaV and I am a Chief AI Engineer', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello VaibhaV! It‚Äôs great to meet you. How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says: \"Hi , My name is VaibhaV and I am a Chief AI Engineer\". Likely they are just greeting. The assistant should respond politely. No policy issues.'}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 87, 'total_tokens': 156, 'completion_time': 0.148574634, 'completion_tokens_details': {'reasoning_tokens': 40}, 'prompt_time': 0.003219431, 'prompt_tokens_details': None, 'queue_time': 0.051090589, 'total_time': 0.151794065}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--dfb9f81d-6f1a-44dd-8ae7-d960c3ac17c2-0', usage_metadata={'input_tokens': 87, 'output_tokens': 69, 'total_tokens': 156, 'output_token_details': {'reasoning': 40}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is VaibhaV.', additional_kwargs={'reasoning_content': 'User asks \"What\\'s my name?\" They introduced themselves as VaibhaV. So answer: VaibhaV.'}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 121, 'total_tokens': 163, 'completion_time': 0.087330393, 'completion_tokens_details': {'reasoning_tokens': 25}, 'prompt_time': 0.004643322, 'prompt_tokens_details': None, 'queue_time': 0.051253518, 'total_time': 0.091973715}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ede716ed-7410-40ac-8ef8-d647e809ad55-0', usage_metadata={'input_tokens': 121, 'output_tokens': 42, 'total_tokens': 163, 'output_token_details': {'reasoning': 25}})])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don‚Äôt have any information about your name. If you‚Äôd like, you can tell me what you‚Äôd like to be called, and I‚Äôll use that going forward!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config-->session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi , My name is VaibhaV and I am a Chief AI Engineer', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello VaibhaV! It‚Äôs great to meet you. How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says: \"Hi , My name is VaibhaV and I am a Chief AI Engineer\". Likely they are just greeting. The assistant should respond politely. No policy issues.'}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 87, 'total_tokens': 156, 'completion_time': 0.148574634, 'completion_tokens_details': {'reasoning_tokens': 40}, 'prompt_time': 0.003219431, 'prompt_tokens_details': None, 'queue_time': 0.051090589, 'total_time': 0.151794065}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--dfb9f81d-6f1a-44dd-8ae7-d960c3ac17c2-0', usage_metadata={'input_tokens': 87, 'output_tokens': 69, 'total_tokens': 156, 'output_token_details': {'reasoning': 40}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is VaibhaV.', additional_kwargs={'reasoning_content': 'User asks \"What\\'s my name?\" They introduced themselves as VaibhaV. So answer: VaibhaV.'}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 121, 'total_tokens': 163, 'completion_time': 0.087330393, 'completion_tokens_details': {'reasoning_tokens': 25}, 'prompt_time': 0.004643322, 'prompt_tokens_details': None, 'queue_time': 0.051253518, 'total_time': 0.091973715}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ede716ed-7410-40ac-8ef8-d647e809ad55-0', usage_metadata={'input_tokens': 121, 'output_tokens': 42, 'total_tokens': 163, 'output_token_details': {'reasoning': 25}})]),\n",
       " 'chat2': InMemoryChatMessageHistory(messages=[HumanMessage(content='Whats my name', additional_kwargs={}, response_metadata={}), AIMessage(content='I don‚Äôt have any information about your name. If you‚Äôd like, you can tell me what you‚Äôd like to be called, and I‚Äôll use that going forward!', additional_kwargs={'reasoning_content': 'We need to respond. The user asks \"Whats my name\". We have no prior conversation storing user info. According to policy, we cannot guess personal info. We should respond that we don\\'t know their name. Offer to ask them.'}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 74, 'total_tokens': 166, 'completion_time': 0.191156651, 'completion_tokens_details': {'reasoning_tokens': 48}, 'prompt_time': 0.002874602, 'prompt_tokens_details': None, 'queue_time': 0.051188328, 'total_time': 0.194031253}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--917e6a62-2783-4c13-bc0b-52cd9bbf6472-0', usage_metadata={'input_tokens': 74, 'output_tokens': 92, 'total_tokens': 166, 'output_token_details': {'reasoning': 48}})])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, John! How can I assist you today?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is John\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi , My name is VaibhaV and I am a Chief AI Engineer', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello VaibhaV! It‚Äôs great to meet you. How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says: \"Hi , My name is VaibhaV and I am a Chief AI Engineer\". Likely they are just greeting. The assistant should respond politely. No policy issues.'}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 87, 'total_tokens': 156, 'completion_time': 0.148574634, 'completion_tokens_details': {'reasoning_tokens': 40}, 'prompt_time': 0.003219431, 'prompt_tokens_details': None, 'queue_time': 0.051090589, 'total_time': 0.151794065}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--dfb9f81d-6f1a-44dd-8ae7-d960c3ac17c2-0', usage_metadata={'input_tokens': 87, 'output_tokens': 69, 'total_tokens': 156, 'output_token_details': {'reasoning': 40}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is VaibhaV.', additional_kwargs={'reasoning_content': 'User asks \"What\\'s my name?\" They introduced themselves as VaibhaV. So answer: VaibhaV.'}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 121, 'total_tokens': 163, 'completion_time': 0.087330393, 'completion_tokens_details': {'reasoning_tokens': 25}, 'prompt_time': 0.004643322, 'prompt_tokens_details': None, 'queue_time': 0.051253518, 'total_time': 0.091973715}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ede716ed-7410-40ac-8ef8-d647e809ad55-0', usage_metadata={'input_tokens': 121, 'output_tokens': 42, 'total_tokens': 163, 'output_token_details': {'reasoning': 25}})]),\n",
       " 'chat2': InMemoryChatMessageHistory(messages=[HumanMessage(content='Whats my name', additional_kwargs={}, response_metadata={}), AIMessage(content='I don‚Äôt have any information about your name. If you‚Äôd like, you can tell me what you‚Äôd like to be called, and I‚Äôll use that going forward!', additional_kwargs={'reasoning_content': 'We need to respond. The user asks \"Whats my name\". We have no prior conversation storing user info. According to policy, we cannot guess personal info. We should respond that we don\\'t know their name. Offer to ask them.'}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 74, 'total_tokens': 166, 'completion_time': 0.191156651, 'completion_tokens_details': {'reasoning_tokens': 48}, 'prompt_time': 0.002874602, 'prompt_tokens_details': None, 'queue_time': 0.051188328, 'total_time': 0.194031253}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--917e6a62-2783-4c13-bc0b-52cd9bbf6472-0', usage_metadata={'input_tokens': 74, 'output_tokens': 92, 'total_tokens': 166, 'output_token_details': {'reasoning': 48}}), HumanMessage(content='Hey My name is John', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, John! How can I assist you today?', additional_kwargs={'reasoning_content': 'We need to respond acknowledging name John, maybe ask how can help.'}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 124, 'total_tokens': 162, 'completion_time': 0.079767077, 'completion_tokens_details': {'reasoning_tokens': 15}, 'prompt_time': 0.005371368, 'prompt_tokens_details': None, 'queue_time': 0.050870942, 'total_time': 0.085138445}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--d8118c0f-17de-4dee-bd2a-863766e740a3-0', usage_metadata={'input_tokens': 124, 'output_tokens': 38, 'total_tokens': 162, 'output_token_details': {'reasoning': 15}})])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is John.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Answer all the question to the nest of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello VaibhaV! üëã Nice to meet you. How can I help you today?', additional_kwargs={'reasoning_content': 'We need to respond. The user says \"Hi My name is VaibhaV\". Probably a greeting. We can respond politely, ask how can help. Use friendly tone.'}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 98, 'total_tokens': 164, 'completion_time': 0.136203852, 'completion_tokens_details': {'reasoning_tokens': 37}, 'prompt_time': 0.00365894, 'prompt_tokens_details': None, 'queue_time': 0.05096239, 'total_time': 0.139862792}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_e88ce9c728', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--f05f9af9-e63e-4988-8b39-04ff8c1939fb-0', usage_metadata={'input_tokens': 98, 'output_tokens': 66, 'total_tokens': 164, 'output_token_details': {'reasoning': 37}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is VaibhaV\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello VaibhaV! Nice to meet you. How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says: \"Hi My name is VaibhaV Arde\". Likely they are greeting and introducing themselves. The assistant should respond politely, perhaps ask how can help. No request for disallowed content. So respond friendly.'}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 100, 'total_tokens': 176, 'completion_time': 0.161337164, 'completion_tokens_details': {'reasoning_tokens': 49}, 'prompt_time': 0.003796666, 'prompt_tokens_details': None, 'queue_time': 0.049855363, 'total_time': 0.16513383}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--525108e7-14eb-4550-9987-8ce57f7db292-0', usage_metadata={'input_tokens': 100, 'output_tokens': 76, 'total_tokens': 176, 'output_token_details': {'reasoning': 49}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is VaibhaV Arde\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi , My name is VaibhaV and I am a Chief AI Engineer', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello VaibhaV! It‚Äôs great to meet you. How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says: \"Hi , My name is VaibhaV and I am a Chief AI Engineer\". Likely they are just greeting. The assistant should respond politely. No policy issues.'}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 87, 'total_tokens': 156, 'completion_time': 0.148574634, 'completion_tokens_details': {'reasoning_tokens': 40}, 'prompt_time': 0.003219431, 'prompt_tokens_details': None, 'queue_time': 0.051090589, 'total_time': 0.151794065}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--dfb9f81d-6f1a-44dd-8ae7-d960c3ac17c2-0', usage_metadata={'input_tokens': 87, 'output_tokens': 69, 'total_tokens': 156, 'output_token_details': {'reasoning': 40}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is VaibhaV.', additional_kwargs={'reasoning_content': 'User asks \"What\\'s my name?\" They introduced themselves as VaibhaV. So answer: VaibhaV.'}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 121, 'total_tokens': 163, 'completion_time': 0.087330393, 'completion_tokens_details': {'reasoning_tokens': 25}, 'prompt_time': 0.004643322, 'prompt_tokens_details': None, 'queue_time': 0.051253518, 'total_time': 0.091973715}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ede716ed-7410-40ac-8ef8-d647e809ad55-0', usage_metadata={'input_tokens': 121, 'output_tokens': 42, 'total_tokens': 163, 'output_token_details': {'reasoning': 25}})]),\n",
       " 'chat2': InMemoryChatMessageHistory(messages=[HumanMessage(content='Whats my name', additional_kwargs={}, response_metadata={}), AIMessage(content='I don‚Äôt have any information about your name. If you‚Äôd like, you can tell me what you‚Äôd like to be called, and I‚Äôll use that going forward!', additional_kwargs={'reasoning_content': 'We need to respond. The user asks \"Whats my name\". We have no prior conversation storing user info. According to policy, we cannot guess personal info. We should respond that we don\\'t know their name. Offer to ask them.'}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 74, 'total_tokens': 166, 'completion_time': 0.191156651, 'completion_tokens_details': {'reasoning_tokens': 48}, 'prompt_time': 0.002874602, 'prompt_tokens_details': None, 'queue_time': 0.051188328, 'total_time': 0.194031253}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--917e6a62-2783-4c13-bc0b-52cd9bbf6472-0', usage_metadata={'input_tokens': 74, 'output_tokens': 92, 'total_tokens': 166, 'output_token_details': {'reasoning': 48}}), HumanMessage(content='Hey My name is John', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, John! How can I assist you today?', additional_kwargs={'reasoning_content': 'We need to respond acknowledging name John, maybe ask how can help.'}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 124, 'total_tokens': 162, 'completion_time': 0.079767077, 'completion_tokens_details': {'reasoning_tokens': 15}, 'prompt_time': 0.005371368, 'prompt_tokens_details': None, 'queue_time': 0.050870942, 'total_time': 0.085138445}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--d8118c0f-17de-4dee-bd2a-863766e740a3-0', usage_metadata={'input_tokens': 124, 'output_tokens': 38, 'total_tokens': 162, 'output_token_details': {'reasoning': 15}}), HumanMessage(content='Whats my name', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is John.', additional_kwargs={'reasoning_content': 'User asks again \"Whats my name\". The assistant should respond with the name stored from previous turn: John. Should confirm.'}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 151, 'total_tokens': 191, 'completion_time': 0.082482053, 'completion_tokens_details': {'reasoning_tokens': 26}, 'prompt_time': 0.005736204, 'prompt_tokens_details': None, 'queue_time': 0.050920646, 'total_time': 0.088218257}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--cf6e065d-7539-455f-badc-bd048fb5081c-0', usage_metadata={'input_tokens': 151, 'output_tokens': 40, 'total_tokens': 191, 'output_token_details': {'reasoning': 26}})]),\n",
       " 'chat3': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi My name is VaibhaV Arde', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello VaibhaV! Nice to meet you. How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says: \"Hi My name is VaibhaV Arde\". Likely they are greeting and introducing themselves. The assistant should respond politely, perhaps ask how can help. No request for disallowed content. So respond friendly.'}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 100, 'total_tokens': 176, 'completion_time': 0.161337164, 'completion_tokens_details': {'reasoning_tokens': 49}, 'prompt_time': 0.003796666, 'prompt_tokens_details': None, 'queue_time': 0.049855363, 'total_time': 0.16513383}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--525108e7-14eb-4550-9987-8ce57f7db292-0', usage_metadata={'input_tokens': 100, 'output_tokens': 76, 'total_tokens': 176, 'output_token_details': {'reasoning': 49}})])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is **VaibhaV\\u202fArde**. Let me know if there‚Äôs anything else you‚Äôd like help with!'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§µ‡•à‡§≠‡§µ! ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Vaibhav\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now wrap this more complicated chain in a Message History class. This time, because there are multiple keys in the input, we need to specify the correct key to use to save the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§Æ‡•Ä‡§∞‡§æ! ‡§Ü‡§™‡§∏‡•á ‡§Æ‡§ø‡§≤‡§ï‡§∞ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•Å‡§à‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ/‡§∏‡§ï‡§§‡•Ä ‡§π‡•Ç‡§Å?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "repsonse=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Hi,I am Meera\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Hindi\"},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§Æ‡•Ä‡§∞‡§æ ‡§π‡•à‡•§'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi , My name is VaibhaV and I am a Chief AI Engineer', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello VaibhaV! It‚Äôs great to meet you. How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says: \"Hi , My name is VaibhaV and I am a Chief AI Engineer\". Likely they are just greeting. The assistant should respond politely. No policy issues.'}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 87, 'total_tokens': 156, 'completion_time': 0.148574634, 'completion_tokens_details': {'reasoning_tokens': 40}, 'prompt_time': 0.003219431, 'prompt_tokens_details': None, 'queue_time': 0.051090589, 'total_time': 0.151794065}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--dfb9f81d-6f1a-44dd-8ae7-d960c3ac17c2-0', usage_metadata={'input_tokens': 87, 'output_tokens': 69, 'total_tokens': 156, 'output_token_details': {'reasoning': 40}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is VaibhaV.', additional_kwargs={'reasoning_content': 'User asks \"What\\'s my name?\" They introduced themselves as VaibhaV. So answer: VaibhaV.'}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 121, 'total_tokens': 163, 'completion_time': 0.087330393, 'completion_tokens_details': {'reasoning_tokens': 25}, 'prompt_time': 0.004643322, 'prompt_tokens_details': None, 'queue_time': 0.051253518, 'total_time': 0.091973715}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ede716ed-7410-40ac-8ef8-d647e809ad55-0', usage_metadata={'input_tokens': 121, 'output_tokens': 42, 'total_tokens': 163, 'output_token_details': {'reasoning': 25}})]),\n",
       " 'chat2': InMemoryChatMessageHistory(messages=[HumanMessage(content='Whats my name', additional_kwargs={}, response_metadata={}), AIMessage(content='I don‚Äôt have any information about your name. If you‚Äôd like, you can tell me what you‚Äôd like to be called, and I‚Äôll use that going forward!', additional_kwargs={'reasoning_content': 'We need to respond. The user asks \"Whats my name\". We have no prior conversation storing user info. According to policy, we cannot guess personal info. We should respond that we don\\'t know their name. Offer to ask them.'}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 74, 'total_tokens': 166, 'completion_time': 0.191156651, 'completion_tokens_details': {'reasoning_tokens': 48}, 'prompt_time': 0.002874602, 'prompt_tokens_details': None, 'queue_time': 0.051188328, 'total_time': 0.194031253}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--917e6a62-2783-4c13-bc0b-52cd9bbf6472-0', usage_metadata={'input_tokens': 74, 'output_tokens': 92, 'total_tokens': 166, 'output_token_details': {'reasoning': 48}}), HumanMessage(content='Hey My name is John', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, John! How can I assist you today?', additional_kwargs={'reasoning_content': 'We need to respond acknowledging name John, maybe ask how can help.'}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 124, 'total_tokens': 162, 'completion_time': 0.079767077, 'completion_tokens_details': {'reasoning_tokens': 15}, 'prompt_time': 0.005371368, 'prompt_tokens_details': None, 'queue_time': 0.050870942, 'total_time': 0.085138445}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--d8118c0f-17de-4dee-bd2a-863766e740a3-0', usage_metadata={'input_tokens': 124, 'output_tokens': 38, 'total_tokens': 162, 'output_token_details': {'reasoning': 15}}), HumanMessage(content='Whats my name', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is John.', additional_kwargs={'reasoning_content': 'User asks again \"Whats my name\". The assistant should respond with the name stored from previous turn: John. Should confirm.'}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 151, 'total_tokens': 191, 'completion_time': 0.082482053, 'completion_tokens_details': {'reasoning_tokens': 26}, 'prompt_time': 0.005736204, 'prompt_tokens_details': None, 'queue_time': 0.050920646, 'total_time': 0.088218257}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--cf6e065d-7539-455f-badc-bd048fb5081c-0', usage_metadata={'input_tokens': 151, 'output_tokens': 40, 'total_tokens': 191, 'output_token_details': {'reasoning': 26}})]),\n",
       " 'chat3': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi My name is VaibhaV Arde', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello VaibhaV! Nice to meet you. How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says: \"Hi My name is VaibhaV Arde\". Likely they are greeting and introducing themselves. The assistant should respond politely, perhaps ask how can help. No request for disallowed content. So respond friendly.'}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 100, 'total_tokens': 176, 'completion_time': 0.161337164, 'completion_tokens_details': {'reasoning_tokens': 49}, 'prompt_time': 0.003796666, 'prompt_tokens_details': None, 'queue_time': 0.049855363, 'total_time': 0.16513383}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--525108e7-14eb-4550-9987-8ce57f7db292-0', usage_metadata={'input_tokens': 100, 'output_tokens': 76, 'total_tokens': 176, 'output_token_details': {'reasoning': 49}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is **VaibhaV\\u202fArde**.', additional_kwargs={'reasoning_content': 'The user asks \"What\\'s my name?\" We have the conversation: user said \"Hi My name is VaibhaV Arde\". So the name is VaibhaV Arde. We answer.'}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 132, 'total_tokens': 196, 'completion_time': 0.132623675, 'completion_tokens_details': {'reasoning_tokens': 42}, 'prompt_time': 0.004947248, 'prompt_tokens_details': None, 'queue_time': 0.050552831, 'total_time': 0.137570923}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_e88ce9c728', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--73e43864-49ff-41f9-977e-f3a08e21187b-0', usage_metadata={'input_tokens': 132, 'output_tokens': 64, 'total_tokens': 196, 'output_token_details': {'reasoning': 42}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is **VaibhaV\\u202fArde**. Let me know if there‚Äôs anything else you‚Äôd like help with!', additional_kwargs={'reasoning_content': 'The user asks again. We should answer. Possibly ask if they want anything else. Simple.'}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 159, 'total_tokens': 215, 'completion_time': 0.116857902, 'completion_tokens_details': {'reasoning_tokens': 20}, 'prompt_time': 0.017150113, 'prompt_tokens_details': None, 'queue_time': 0.051310606, 'total_time': 0.134008015}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_1d1727abc9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--6b318349-4fc3-4f53-8151-47e76d0c5c76-0', usage_metadata={'input_tokens': 159, 'output_tokens': 56, 'total_tokens': 215, 'output_token_details': {'reasoning': 20}})]),\n",
       " 'chat4': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi,I am Meera', additional_kwargs={}, response_metadata={}), AIMessage(content='‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§Æ‡•Ä‡§∞‡§æ! ‡§Ü‡§™‡§∏‡•á ‡§Æ‡§ø‡§≤‡§ï‡§∞ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•Å‡§à‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ/‡§∏‡§ï‡§§‡•Ä ‡§π‡•Ç‡§Å?', additional_kwargs={'reasoning_content': 'We need to respond in Hindi, greeting Meera. Should be helpful.'}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 97, 'total_tokens': 148, 'completion_time': 0.110565348, 'completion_tokens_details': {'reasoning_tokens': 16}, 'prompt_time': 0.004165476, 'prompt_tokens_details': None, 'queue_time': 0.051129694, 'total_time': 0.114730824}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_70d048ba3c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7041438a-0c2c-4854-8599-3674564184a5-0', usage_metadata={'input_tokens': 97, 'output_tokens': 51, 'total_tokens': 148, 'output_token_details': {'reasoning': 16}}), HumanMessage(content='whats my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§Æ‡•Ä‡§∞‡§æ ‡§π‡•à‡•§', additional_kwargs={'reasoning_content': 'The user asks \"whats my name?\" The assistant should respond in Hindi, per developer instruction. The assistant knows from conversation that user introduced as Meera. So answer: \"‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§Æ‡•Ä‡§∞‡§æ ‡§π‡•à\". Provide in Hindi.'}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 138, 'total_tokens': 202, 'completion_time': 0.133343186, 'completion_tokens_details': {'reasoning_tokens': 48}, 'prompt_time': 0.005185716, 'prompt_tokens_details': None, 'queue_time': 0.050537524, 'total_time': 0.138528902}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--e0085788-61a0-4609-87ef-1631231fd6a6-0', usage_metadata={'input_tokens': 138, 'output_tokens': 64, 'total_tokens': 202, 'output_token_details': {'reasoning': 48}})])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§§‡•Å‡§Æ‡§ö‡•á ‡§®‡§æ‡§µ **‡§µ‡•à‡§≠‡§µ** ‡§Ü‡§π‡•á.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Waht is my name?\")], \"language\":\"Marathi\"},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing the Conversation History\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "'trim_messages' helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I‚Äôm not sure which flavor you prefer‚Äîcould you tell me your favorite ice‚Äëcream flavor? Once I know, I can chat about it or suggest similar ones you might enjoy!'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked about the sum\\u202f2\\u202f+\\u202f2.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap this in the MEssage History\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don‚Äôt have any information about your name. If you‚Äôd like to share it, feel free to let me know!'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You haven‚Äôt actually asked a math problem yet. If you have a specific question or problem in mind, feel free to share it and I‚Äôll be happy to help!'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentnotes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
